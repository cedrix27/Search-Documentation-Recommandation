# =============================
# üõ°Ô∏è Contournement du bug Streamlit + torch
# =============================
import os
os.environ["STREAMLIT_WATCHER_TYPE"] = "none"

# =============================
# üì¶ Imports
# =============================
import streamlit as st
import faiss
import pandas as pd
import pickle
from sentence_transformers import SentenceTransformer

# =============================
# 1Ô∏è‚É£ - Chargement des mod√®les
# =============================
st.title("üîé Search Documentation Recommender")

# Chargement du mod√®le SBERT
st.sidebar.subheader("Chargement du mod√®le...")
model = SentenceTransformer('all-MiniLM-L6-v2')
#with open('sbert_model.pkl', 'rb') as f:
    #model = pickle.load(f)
st.sidebar.success("Mod√®le SBERT charg√© !")

# Chargement de l'index Faiss
st.sidebar.subheader("Chargement de l'index...")
index = faiss.read_index('faiss_index.index')
st.sidebar.success("Index Faiss charg√© !")

# Chargement de ton fichier CSV
st.sidebar.subheader("Chargement des articles...")
documents = pd.read_csv('arxiv_articles_nettoye.csv')
st.sidebar.success(f"{len(documents)} articles charg√©s !")

# =============================
# 2Ô∏è‚É£ - Fonction de recherche
# =============================
def search_similar_documents(query, model, index, documents, top_k=5):
    query_vector = model.encode([query])
    distances, indices = index.search(query_vector, top_k)

    results = []
    for i, idx in enumerate(indices[0]):
        results.append({
            'Titre': documents.iloc[idx]['Titre'],
            'R√©sum√©': documents.iloc[idx]['R√©sum√©'],
            'Lien PDF': documents.iloc[idx]['Lien PDF'],
            'Sujet': documents.iloc[idx]['Sujet'],
            'Distance': distances[0][i]
        })
    return results

# =============================
# 3Ô∏è‚É£ - Interface de recherche
# =============================
st.subheader("üîé Recherche de documents")
query = st.text_input("Entrez un mot-cl√©, un sujet ou un r√©sum√© :")

if query:
    st.write("Recherche en cours...")
    results = search_similar_documents(query, model, index, documents, top_k=5)

    for res in results:
        st.markdown(f"### üìå {res['Titre']}")
        st.write(f"**Sujet** : {res['Sujet']}")
        st.write(f"**R√©sum√©** : {res['R√©sum√©']}")
        st.markdown(f"[üìÑ Lire l'article complet]({res['Lien PDF']})", unsafe_allow_html=True)
        st.divider()

